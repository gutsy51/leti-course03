{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "JkGNDCaLEn4L",
    "ExecuteTime": {
     "end_time": "2025-01-27T20:00:31.338016Z",
     "start_time": "2025-01-27T20:00:31.334221Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy\n",
    "\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PiYwq_67En4R",
    "outputId": "9a0a75f6-a2c9-4a88-eacb-a0917085b599",
    "ExecuteTime": {
     "end_time": "2025-01-27T20:00:31.432567Z",
     "start_time": "2025-01-27T20:00:31.426898Z"
    }
   },
   "source": [
    "torch.device('cuda')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_EnVuCgvEn4R",
    "ExecuteTime": {
     "end_time": "2025-01-27T20:00:31.465663Z",
     "start_time": "2025-01-27T20:00:31.456811Z"
    }
   },
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output\n"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cMQuYu7TEn4R",
    "ExecuteTime": {
     "end_time": "2025-01-27T20:00:31.493762Z",
     "start_time": "2025-01-27T20:00:31.489668Z"
    }
   },
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zSSAussPEn4R",
    "ExecuteTime": {
     "end_time": "2025-01-27T20:00:31.512296Z",
     "start_time": "2025-01-27T20:00:31.508176Z"
    }
   },
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CSQoGqDJEn4S",
    "ExecuteTime": {
     "end_time": "2025-01-27T20:03:18.536562Z",
     "start_time": "2025-01-27T20:03:18.532376Z"
    }
   },
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x\n"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QjQvhHVkEn4S",
    "ExecuteTime": {
     "end_time": "2025-01-27T20:03:19.634912Z",
     "start_time": "2025-01-27T20:03:19.631057Z"
    }
   },
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        cross_attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(cross_attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "adKPbwEhEn4S",
    "ExecuteTime": {
     "end_time": "2025-01-27T20:03:21.340157Z",
     "start_time": "2025-01-27T20:03:21.334381Z"
    }
   },
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout, device):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.device = device\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2).to(self.device)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3).to(self.device)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "        tgt_mask = tgt_mask & nopeak_mask.to(self.device)\n",
    "\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output)\n",
    "        return output"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "alW27ZaHEn4S",
    "ExecuteTime": {
     "end_time": "2025-01-27T20:03:27.789054Z",
     "start_time": "2025-01-27T20:03:23.536778Z"
    }
   },
   "source": [
    "src_vocab_size = 500000\n",
    "tgt_vocab_size = 500000\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "max_seq_length = 50\n",
    "dropout = 0.1\n",
    "device = \"cpu\"\n",
    "\n",
    "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout,  device)\n",
    "transformer = transformer.to(device)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wRfSAcZ5C-UU",
    "ExecuteTime": {
     "end_time": "2025-01-27T20:03:36.161475Z",
     "start_time": "2025-01-27T20:03:36.155120Z"
    }
   },
   "source": [
    "# start_token = torch.tensor([1999], dtype=torch.int64)"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1xYpjiUbE1SA",
    "ExecuteTime": {
     "end_time": "2025-01-27T20:03:36.881950Z",
     "start_time": "2025-01-27T20:03:36.878530Z"
    }
   },
   "source": [
    "from random import randint"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yD6ZE07dtmQC",
    "ExecuteTime": {
     "end_time": "2025-01-27T20:03:57.377636Z",
     "start_time": "2025-01-27T20:03:57.373933Z"
    }
   },
   "source": [
    "def generate_sample_10():\n",
    "    # start^3, (start+1)^3 ...    start = randint(1, 500)\n",
    "    start = 1\n",
    "    extra = 10\n",
    "    src = torch.tensor([i**2 for i in range(start, start+max_seq_length+extra)], dtype=torch.int64)\n",
    "    trg = torch.tensor([(i+1)**2 for i in range(start, start+max_seq_length+extra)], dtype=torch.int64)\n",
    "    labels = trg[1:]\n",
    "\n",
    "    return src[:max_seq_length], trg[:max_seq_length], labels[:max_seq_length]\n"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SBIkGJa2E1SA",
    "ExecuteTime": {
     "end_time": "2025-01-27T20:03:59.289063Z",
     "start_time": "2025-01-27T20:03:59.242280Z"
    }
   },
   "source": [
    "src_batch, trg_batch, labels = generate_sample_10()\n",
    "print(src_batch, len(src_batch))\n",
    "print(trg_batch, len(trg_batch))\n",
    "print(labels, len(labels))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([   1,    4,    9,   16,   25,   36,   49,   64,   81,  100,  121,  144,\n",
      "         169,  196,  225,  256,  289,  324,  361,  400,  441,  484,  529,  576,\n",
      "         625,  676,  729,  784,  841,  900,  961, 1024, 1089, 1156, 1225, 1296,\n",
      "        1369, 1444, 1521, 1600, 1681, 1764, 1849, 1936, 2025, 2116, 2209, 2304,\n",
      "        2401, 2500]) 50\n",
      "tensor([   4,    9,   16,   25,   36,   49,   64,   81,  100,  121,  144,  169,\n",
      "         196,  225,  256,  289,  324,  361,  400,  441,  484,  529,  576,  625,\n",
      "         676,  729,  784,  841,  900,  961, 1024, 1089, 1156, 1225, 1296, 1369,\n",
      "        1444, 1521, 1600, 1681, 1764, 1849, 1936, 2025, 2116, 2209, 2304, 2401,\n",
      "        2500, 2601]) 50\n",
      "tensor([   9,   16,   25,   36,   49,   64,   81,  100,  121,  144,  169,  196,\n",
      "         225,  256,  289,  324,  361,  400,  441,  484,  529,  576,  625,  676,\n",
      "         729,  784,  841,  900,  961, 1024, 1089, 1156, 1225, 1296, 1369, 1444,\n",
      "        1521, 1600, 1681, 1764, 1849, 1936, 2025, 2116, 2209, 2304, 2401, 2500,\n",
      "        2601, 2704]) 50\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UAS_IhBcE1SB",
    "ExecuteTime": {
     "end_time": "2025-01-27T20:04:01.516521Z",
     "start_time": "2025-01-27T20:04:01.512765Z"
    }
   },
   "source": [
    "def generate_batch(batch_size: int = 128):\n",
    "    src_batch = torch.tensor([], dtype=torch.int64)\n",
    "    trg_batch = torch.tensor([], dtype=torch.int64)\n",
    "    labels_batch = torch.tensor([], dtype=torch.int64)\n",
    "\n",
    "    while src_batch.shape[0] < batch_size:\n",
    "        src_sample, trg_sample, labels_sample = generate_sample_10()\n",
    "        src_batch = torch.cat((src_batch, src_sample.unsqueeze(0)))\n",
    "        trg_batch = torch.cat((trg_batch, trg_sample.unsqueeze(0)))\n",
    "        labels_batch = torch.cat((labels_batch, labels_sample.unsqueeze(0)))\n",
    "\n",
    "    return src_batch, trg_batch, labels_batch\n"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NJQSp6DrE1SB",
    "ExecuteTime": {
     "end_time": "2025-01-27T20:06:40.742080Z",
     "start_time": "2025-01-27T20:04:03.158444Z"
    }
   },
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "transformer.train()\n",
    "train_loss_history = []\n",
    "\n",
    "for step in tqdm(range(100)):\n",
    "    src_batch, trg_batch, labels_batch = generate_batch(64)\n",
    "    optimizer.zero_grad()\n",
    "    output = transformer(src_batch.to(device), trg_batch.to(device))\n",
    "    loss = criterion(output.view(-1, output.size(-1)), labels_batch.to(device).view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    train_loss_history.append(loss.item())\n",
    "    print(f\"Step: {step+1}, Loss: {loss.item()}\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [02:34<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 6400000000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 12\u001B[0m\n\u001B[0;32m     10\u001B[0m output \u001B[38;5;241m=\u001B[39m transformer(src_batch\u001B[38;5;241m.\u001B[39mto(device), trg_batch\u001B[38;5;241m.\u001B[39mto(device))\n\u001B[0;32m     11\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(output\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, output\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)), labels_batch\u001B[38;5;241m.\u001B[39mto(device)\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m---> 12\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     14\u001B[0m train_loss_history\u001B[38;5;241m.\u001B[39mappend(loss\u001B[38;5;241m.\u001B[39mitem())\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:581\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    572\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    573\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    574\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    579\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    580\u001B[0m     )\n\u001B[1;32m--> 581\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    582\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    583\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    823\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    827\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    828\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    829\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: [enforce fail at alloc_cpu.cpp:114] data. DefaultCPUAllocator: not enough memory: you tried to allocate 6400000000 bytes."
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hFMeIDmDkrs"
   },
   "source": [
    "# Visualize train loss"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YeP9vU1FDDh1"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jphi2crTDE3w"
   },
   "source": [
    "# Define X and Y variable data\n",
    "x = np.array(list(range(len(train_loss_history))))\n",
    "y = np.array(train_loss_history)\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"Steps\")  # add X-axis label\n",
    "plt.ylabel(\"Train loss\")  # add Y-axis label\n",
    "plt.title(\"Training\")  # add title\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9iFYH6ubDpkW"
   },
   "source": [
    "# Make batches for inference"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9sEAgV4KE1SD"
   },
   "source": [
    "transformer.eval()\n",
    "src_batch, trg_batch, labels_batch = generate_batch(64)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1DinGODmE1SE"
   },
   "source": [
    "preds_batch = torch.zeros_like(labels_batch)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1RPofznyE1SE",
    "ExecuteTime": {
     "end_time": "2025-01-27T20:00:34.614606Z",
     "start_time": "2025-01-27T20:00:34.613606Z"
    }
   },
   "source": [
    "# predict from first token\n",
    "trg_batch[:,1:] = torch.full(trg_batch[:,1:].shape, 0)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhGc6H4vDsLu"
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aOQ--46yDMuY",
    "ExecuteTime": {
     "end_time": "2025-01-27T20:00:34.615606Z",
     "start_time": "2025-01-27T20:00:34.615606Z"
    }
   },
   "source": [
    "# generating cycle\n",
    "for i in range(trg_batch.shape[1]):\n",
    "    res = transformer(src_batch.to(device), trg_batch.to(device))\n",
    "    preds_batch[:,i] = res[:,i].argmax(dim=1)\n",
    "\n",
    "    if i < trg_batch.shape[1]-1:\n",
    "        trg_batch[:,i+1] = res[:,i].argmax(dim=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "08G1VAfkDNiw",
    "outputId": "01478923-d925-45fe-805f-4658010953c5"
   },
   "source": [
    "preds_batch"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U5QAiPKTDNyz",
    "outputId": "385d5d49-6e97-47ed-da36-87880261e7a9"
   },
   "source": [
    "trg_batch"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iALwEPdHDTbB"
   },
   "source": [
    "# Compare labels and preds here"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "X4m9vh63xxuc"
   },
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "m7y6_ELUxVb_",
    "ExecuteTime": {
     "end_time": "2025-01-27T20:00:34.621606Z",
     "start_time": "2025-01-27T20:00:34.620606Z"
    }
   },
   "source": [
    "preds = preds_batch.view(-1).cpu().numpy()\n",
    "labels = labels_batch.view(-1).cpu().numpy()\n",
    "\n",
    "accuracy = accuracy_score(labels, preds)\n",
    "precision = precision_score(labels, preds, average='weighted')\n",
    "recall = recall_score(labels, preds, average='weighted')\n",
    "f1 = f1_score(labels, preds, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
